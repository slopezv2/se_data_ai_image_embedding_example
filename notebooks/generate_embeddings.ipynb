{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cc25c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nGenerates vector embeddings for images specified in the 'dataset/dataset.csv'\\nfile using the Azure AI Vision Vectorize Image API. The resulting embeddings\\nare stored in the 'dataset/dataset_embeddings.csv' file.\\n\\nTo execute the script, use the following command from the root folder:\\n`python data_processing/generate_embeddings.py`\\n\\nAuthor: Foteini Savvidou (GitHub @sfoteini)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generates vector embeddings for images specified in the 'dataset/dataset.csv'\n",
    "file using the Azure AI Vision Vectorize Image API. The resulting embeddings\n",
    "are stored in the 'dataset/dataset_embeddings.csv' file.\n",
    "\n",
    "To execute the script, use the following command from the root folder:\n",
    "`python data_processing/generate_embeddings.py`\n",
    "\n",
    "Author: Foteini Savvidou (GitHub @sfoteini)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d492d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251852e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BATCH_SIZE = 1000\n",
    "MAX_WORKERS = 16\n",
    "IMAGE_FILE_CSV_COLUMN_NAME = \"image_file\"\n",
    "EMBEDDINGS_CSV_COLUMN_NAME = \"vector\"\n",
    "# Directories\n",
    "current_dir = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "parent_dir = os.path.dirname(\"../\")\n",
    "\n",
    "# Datasets' folder\n",
    "dataset_folder = os.path.join(parent_dir, \"dataset\")\n",
    "dataset_filepath = os.path.join(dataset_folder, \"dataset.csv\")\n",
    "embeddings_filepath = os.path.join(dataset_folder, \"embeddings.csv\")\n",
    "final_dataset_filepath = os.path.join(dataset_folder, \"dataset_embeddings.csv\")\n",
    "\n",
    "# Images' folder\n",
    "images_folder = os.path.join(parent_dir, \"semart_dataset\", \"images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c7b7665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environemt file\n",
    "load_dotenv(os.path.join(parent_dir, \".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd8b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n",
    "    logging_enable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "682edc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure AI Vision Endpoint: https://agent-ai-serviceswauo.cognitiveservices.azure.com/\n",
      "Connection retrieved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Get the Azure AI Vision connection from AI Foundry project\n",
    "connection = project_client.connections.get(\n",
    "    name=\"aivision\",\n",
    "    include_credentials=True\n",
    ")\n",
    "\n",
    "# Get the connection properties\n",
    "vision_endpoint = connection.get(\"target\")\n",
    "vision_key = connection.credentials.get(\"key\")\n",
    "print(f\"Azure AI Vision Endpoint: {vision_endpoint}\")\n",
    "print(f\"Connection retrieved successfully!\")\n",
    "vision_api_version = os.getenv(\"VISION_VERSION\")\n",
    "vectorize_img_url = vision_endpoint + \"computervision/retrieval:vectorizeImage\" + vision_api_version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c430a1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://agent-ai-serviceswauo.cognitiveservices.azure.com/computervision/retrieval:vectorizeImage?api-version=2024-02-01&model-version=2023-04-15'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75deddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set-up folder and embeddings file\n",
    "    os.makedirs(dataset_folder, exist_ok=True)\n",
    "    if os.path.exists(embeddings_filepath):\n",
    "        os.remove(embeddings_filepath)\n",
    "\n",
    "    # Get the names of image files\n",
    "    image_names = load_image_filenames()\n",
    "    print(f\"Number of images in the dataset: {len(image_names)}\")\n",
    "\n",
    "    # Compute vector embeddings and save them in a csv file\n",
    "    compute_embeddings(image_names)\n",
    "\n",
    "    # Save the final dataset\n",
    "    generate_dataset()\n",
    "\n",
    "\n",
    "def load_image_filenames() -> list[str]:\n",
    "    \"\"\"\n",
    "    Returns a list of filenames for the images in the dataset.\n",
    "\n",
    "    :return: A list containing the filenames of the images.\n",
    "    \"\"\"\n",
    "    with open(dataset_filepath, \"r\") as csv_file:\n",
    "        csv_reader = csv.DictReader(\n",
    "            csv_file,\n",
    "            delimiter=\"\\t\",\n",
    "            skipinitialspace=True,\n",
    "        )\n",
    "        image_filenames = [row[IMAGE_FILE_CSV_COLUMN_NAME] for row in csv_reader]\n",
    "\n",
    "    return image_filenames\n",
    "\n",
    "\n",
    "def get_image_embedding(image: str) -> list[float] | None:\n",
    "    \"\"\"\n",
    "    Generates a vector embedding for an image using Azure AI Vision 4.0\n",
    "    (Vectorize Image API).\n",
    "\n",
    "    :param image: The image filepath.\n",
    "    :return: The vector embedding of the image.\n",
    "    \"\"\"\n",
    "    with open(image, \"rb\") as img:\n",
    "        data = img.read()\n",
    "\n",
    "    headers = {\n",
    "        \"Content-type\": \"application/octet-stream\",\n",
    "        \"Ocp-Apim-Subscription-Key\": vision_key,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.post(vectorize_img_url, data=data, headers=headers)\n",
    "        if r.status_code == 200:\n",
    "            image_vector = r.json()[\"vector\"]\n",
    "            return image_vector\n",
    "        else:\n",
    "            print(\n",
    "                f\"An error occurred while processing {image}. \"\n",
    "                f\"Error code: {r.status_code}.\"\n",
    "            )\n",
    "            print(f\"Error message: {r.text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {image}: {e}\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def compute_embeddings(image_names: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Computes vector embeddings for the provided images and saves the embeddings\n",
    "    alongside their corresponding image filenames in a CSV file.\n",
    "\n",
    "    :param image_names: A list containing the filenames of the images.\n",
    "    \"\"\"\n",
    "    image_names_batches = [\n",
    "        image_names[i:(i + BATCH_SIZE)]\n",
    "        for i in range(0, len(image_names), BATCH_SIZE)\n",
    "    ]\n",
    "    for batch in tqdm(range(len(image_names_batches)), desc=\"Computing embeddings\"):\n",
    "        images = image_names_batches[batch]\n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "            embeddings = list(\n",
    "                tqdm(\n",
    "                    executor.map(\n",
    "                        lambda x: get_image_embedding(\n",
    "                            image=os.path.join(images_folder, x),\n",
    "                        ),\n",
    "                        images,\n",
    "                    ),\n",
    "                    total=len(images),\n",
    "                    desc=f\"Processing batch {batch+1}\",\n",
    "                    leave=False,\n",
    "                )\n",
    "            )\n",
    "        valid_data = [\n",
    "            [images[i], str(embeddings[i])] for i in range(len(images))\n",
    "            if embeddings[i] is not None\n",
    "        ]\n",
    "        save_data_to_csv(valid_data)\n",
    "\n",
    "\n",
    "def save_data_to_csv(data: list[list[str]]) -> None:\n",
    "    \"\"\"\n",
    "    Appends a list of image filenames and their associated embeddings to\n",
    "    a CSV file.\n",
    "\n",
    "    :param data: The data to be appended to the CSV file.\n",
    "    \"\"\"\n",
    "    with open(embeddings_filepath, \"a\", newline=\"\") as csv_file:\n",
    "        write = csv.writer(csv_file)\n",
    "        write.writerows(data)\n",
    "\n",
    "\n",
    "def generate_dataset() -> None:\n",
    "    \"\"\"\n",
    "    Appends the corresponding vectors to each column of the original dataset\n",
    "    and saves the updated dataset as a CSV file.\n",
    "    \"\"\"\n",
    "    dataset_df = pd.read_csv(dataset_filepath, sep=\"\\t\", dtype=\"string\")\n",
    "    embeddings_df = pd.read_csv(\n",
    "        embeddings_filepath,\n",
    "        dtype=\"string\",\n",
    "        names=[IMAGE_FILE_CSV_COLUMN_NAME, EMBEDDINGS_CSV_COLUMN_NAME],\n",
    "    )\n",
    "    final_dataset_df = dataset_df.merge(\n",
    "        embeddings_df, how=\"inner\", on=IMAGE_FILE_CSV_COLUMN_NAME\n",
    "    )\n",
    "    final_dataset_df.to_csv(final_dataset_filepath, index=False, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2458c346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the dataset: 11206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|██████████| 12/12 [35:42<00:00, 178.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se-data-ai-image-embedding-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
